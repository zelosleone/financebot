# ==============================================================================
# FINANCEBOT - Environment Variables Template
# ==============================================================================
# Copy this file to .env.local and fill in your actual values
# DO NOT commit .env.local to version control
# ==============================================================================

# ------------------------------------------------------------------------------
# APP CONFIGURATION
# ------------------------------------------------------------------------------
NEXT_PUBLIC_APP_MODE=development
NEXT_PUBLIC_APP_URL=http://localhost:3000

# ------------------------------------------------------------------------------
# ZHIPU AI GLM (PRIMARY LLM Provider)
# ------------------------------------------------------------------------------
# Zhipu AI's GLM models (GLM-4, GLM-4-Plus, etc.)
GLM_API_KEY=your_glm_api_key_here
GLM_BASE_URL=https://api.z.ai/api/coding/paas/v4
GLM_MODEL=glm-4-plus

# ------------------------------------------------------------------------------
# OPENAI API (OPTIONAL - fallback if GLM not configured)
# ------------------------------------------------------------------------------
# Used for AI chat responses and natural language understanding
# Get your API key at: https://platform.openai.com
OPENAI_API_KEY=sk-your_openai_api_key_here

# ------------------------------------------------------------------------------
# DAYTONA API (REQUIRED for Python code execution)
# ------------------------------------------------------------------------------
# Used for secure Python code execution (data analysis, charts, ML models)
# Get your API key at: https://daytona.io
DAYTONA_API_KEY=your_daytona_api_key_here
DAYTONA_API_URL=https://api.daytona.io
DAYTONA_TARGET=latest

# ------------------------------------------------------------------------------
# LOCAL LLM CONFIGURATION (OPTIONAL)
# ------------------------------------------------------------------------------
# Use Ollama or LM Studio for unlimited, private local AI queries

# Ollama Configuration (https://ollama.com)
OLLAMA_BASE_URL=http://localhost:11434

# LM Studio Configuration (https://lmstudio.ai)
LMSTUDIO_BASE_URL=http://localhost:1234

# ------------------------------------------------------------------------------
# SUPABASE (OPTIONAL - for chat history persistence)
# ------------------------------------------------------------------------------
# App's own Supabase for user data, chat history, etc.
# Get these from: https://supabase.com → Project Settings → API

NEXT_PUBLIC_SUPABASE_URL=https://your-project.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_anon_key_here
SUPABASE_SERVICE_ROLE_KEY=your_service_role_key_here

# ------------------------------------------------------------------------------
# ANALYTICS (OPTIONAL)
# ------------------------------------------------------------------------------
# PostHog for analytics and feature flags
NEXT_PUBLIC_POSTHOG_KEY=your_posthog_key
NEXT_PUBLIC_POSTHOG_HOST=https://eu.i.posthog.com
